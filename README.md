
# CNN for speech denoising
Домашнее задание по курсу [My first data project](https://ods.ai/tracks/my_first_data_project).

Основная цель представленного проекта - решить задачу очистки речи от фоновых шумов, используя технологии машинного обучения.

В описании ниже представлено обоснование выбранной архитектуры, приведены результаты экспериментов по подбору оптимальных гиперпараметров, описан процесс обучения нейронной сети.

## Основные библиотеки

- librosa
- numpy
- tensorflow

## Содержание

Репозиторий состоит из нескольких Jupyter ноутбуков:
- cnn_model_final - описание модели и процесса ее обучения. 
- cnn_model_test - демонстрация работы модели на любом аудио.
- prepare_dataset - ноутбук для преобразования данных для модели. Версия тут - обработка единственной аудиозаписи.

И нескольких .py файлов: приведение cnn_model_final в нормальный вид.

speech_model.h5 - самая последняя версия обученной модели.

## Dataset

Машинное обучение начинается с данных. Итоговый датасет для задачи был сгенерирован на основе следующих наборов:
- Common Voice (https://commonvoice.mozilla.org/ru/datasets). Имеет большое число проверенных аудиозаписей - зачитанных спикерами текстов.
- UrbanSound8K (https://www.kaggle.com/datasets/chrisfilo/urbansound8k). Большой объем разнотипных городских шумов.

Из каждой аудиозаписи отсекается тихий участок (в начале и конце аудиозаписи). Далее, на записи голоса (1 датасет) накладываются выбранные случайным образом (из 2 датасета) шумы, с параметром SNR в диапазоне от 0 до 15 db. После, с преобразованием Фурье, каждое аудио конвертируется в STFT magnitude vectors, которые, после некоторых дополнительных шагов, подаются в сеть (детали описаны в статье, и откомментируются в коде).

*SNR (Signal-to-Distortion) - отношение мощности полезного сигнала к мощности шума.

Детали описаны в статье [1], ссылка в конце документа.

## Подбор гиперпараметров

Сперва стоит отметить, что автор работы столкнулся с техническими ограничениями и не смог организовать обучение моделей с большей вариативностью в значениях гиперпараметров. Эксперименты будут продолжены.

## Инструменты
В качестве основного инструмента версионирования экспериментов была взята платформа Weights and Biases. Процесс подбора гиперпараметров проводился с использованием ее особенностей [sweeps](https://docs.wandb.ai/guides/sweeps) и метода баесовской оптимизации.
Все эксперименты доступны к просмотру в проекте speech_denoising (можно найти в профиле - [ссылка](https://wandb.ai/sams3pi01?shareProfileType=copy)).

Поговорим о самом процессе: 

#### Архитектура нейронной сети
Пара слов об архитектуре, поскольку она имеет прямое влияние на гиперпараметры. 
![image](https://user-images.githubusercontent.com/63301430/232900314-fc11581a-f943-4477-b2fe-03eed911203a.png)

Архитектура заимствована из уже упомянутой выше статьи [1] (следующие снимки оттуда) по нескольким причинам:
- Исследование, описанное в работе, проводилось с целью найти оптимальное с точки зрения числа параметров и качества решение, которое бы функционировало в условиях серьезных аппаратных ограничений (в статье - на слуховом аппарате).
- В исследовании проведено сравнение нескольких архитектур нейронных сетей, выбор был сделан по его итогам.
- CNN демонстрирует высокую производительность в том числе на задачах связанных с обработкой речи, что полезно при размещении модели на смартфоне.
- Уровень сложности реализации.
- Автор данной статьи проявляет интерес к computer vision и обработке изображений. 

*Сравнение работы разных архитектур нейронных сетей в статье:
![image](https://user-images.githubusercontent.com/63301430/232899470-855f6231-0a31-487b-9fbc-e93d7b498d96.png)
![image](https://user-images.githubusercontent.com/63301430/232899557-78e334ed-e9e0-44b2-a8d0-4c10be62fd6a.png)

Выбрана CR-CED (skip), т.к. модель демонстрирует отличные результаты, имея при этом наименьшее число параметров.

Таким образом, число нейронов и число слоев, metric - rmse (широко распространенная для задач регресии, к слову), activation - adam, loss - mse взяты из статьи.

*Если не разрешается взять отсюда архитектуру, к защите постараюсь успеть разработать полностью свое решение.*

## Batch-size

Пока выдвину предположение, что оптимальное значение данного параметра или 256, или 502. 
Предположение основано на изучении сторонних источников и самой успешной попытке обучить модель (ибо там значение лежит в этом диапазоне).

## Learning rate

Изначально значение данного параметра было приравнено к 0.0015, поскольку именно это число приводилось в статье. Однако, из-за разных размеров датасетов (4000 против 1000 - 1500 на эксперимент в нашем случае), стало очевидно, что оно должно быть увеличено, в противном случае, процесс обучения требовал бы еще больше времени и данных.

По итогу, модель со значением параметра в 0.0029 (выбранного, в рамках баесовой оптимизации, случайным образом), показала неплохие результаты и по времени, и по скорости обучения, и по точности модели в результате.

*Следует упомянуть, что в статье приводился вариант обучения лесенкой(?): обучение проводится до тех пор, пока значения validation loss не упираются в какое-либо плато -> полученные веса модели используются на следующем этапе обучения, где значение гиперпараметра принимается за 0.00075 (т.е. делится на два). И следующие шаги выполняются похожим образом (learning_rate / 3, learning_rate / 4). 
Этот способ стал откровением для автора и он не мог его не проверить, см рисунок ниже. 
![W B Chart 4_18_2023, 11 41 13 PM](https://user-images.githubusercontent.com/63301430/232900037-06aaee3f-7ef2-4b86-9df3-edb7bf3e722a.png)

Действительно, следование этому алгоритму позволяет последовательно улучшать метрики модели, хоть и требует дополнительных временных вложений.

## Epochs

Число эпох сильно зависит от приведенных выше гиперпараметров. Пока в них нет предельной ясности, не удастся дать точный ответ и на этот пункт.

Пока за оптимальное значение взят промежуток от 16 до 64. На практике, модели с числом эпох от 30 до 40 показывали неплохие результаты, но делать выводы рано.

# Скрины по экспериментам
![W B Chart 4_18_2023, 11 45 32 PM](https://user-images.githubusercontent.com/63301430/232900974-d28277de-abae-4b4f-bcfe-04e90a299e58.png)

Наилучший результат продемонстрировала модель со следующими параметрами:
![image](https://user-images.githubusercontent.com/63301430/232901120-35429512-8051-4b61-a251-c1dfe9a83679.png)

## References
- https://paperswithcode.com/paper/a-fully-convolutional-neural-network-for
- https://habr.com/ru/post/668518/
- https://habr.com/ru/companies/antiplagiat/articles/528384/
- https://www.youtube.com/watch?v=ZqpSb5p1xQo&list=WL&index=8&t=1072s
- https://www.mathworks.com/help/deeplearning/ug/denoise-speech-using-deep-learning-networks.html
- https://www.kaggle.com/code/danielgraham1997/speech-denoising-analysis#Metrics-Analysis
- https://www.kaggle.com/code/carlolepelaars/bidirectional-lstm-for-audio-labeling-with-keras/notebook
