{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 08:01:27.741179: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-18 08:01:27.783724: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-18 08:01:27.784871: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-18 08:01:28.660235: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import pickle\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Input, BatchNormalization, Activation, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from wandb.keras import WandbMetricsLogger, WandbModelCheckpoint\n",
    "\n",
    "tf.random.set_seed(999)\n",
    "np.random.seed(999)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL PARAMETERS\n",
    "# Comment them all\n",
    "WINDOW_LENGTH = 256\n",
    "# Some comments why i need this variable\n",
    "SAMPLE_RATE = 16000\n",
    "# Why i need this variable\n",
    "N_SEGMENTS = 8\n",
    "# Why i need this variable\n",
    "N_CLEAN_SEGMENTS = 1\n",
    "# Why i need this variable\n",
    "N_FFT = WINDOW_LENGTH\n",
    "# Why i need this variable\n",
    "N_FEATURES = N_FFT//2 + 1\n",
    "# Why i need this variable\n",
    "OVERLAP = round(0.25 * WINDOW_LENGTH)  # overlap of 75%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD PREPARED DATA\n",
    "DATA_PATH = '/run/media/svyatoslav/Files/ml_data_project'\n",
    "\n",
    "x_train = pickle.load(open(DATA_PATH + '/X_training_4.pkl', 'rb'))\n",
    "y_train = pickle.load(open(DATA_PATH + '/Y_training_4.pkl', 'rb'))\n",
    "\n",
    "x_test = pickle.load(open(DATA_PATH + '/X_test_1.pkl', 'rb'))\n",
    "y_test = pickle.load(open(DATA_PATH + '/Y_test_1.pkl', 'rb'))\n",
    "\n",
    "x_val = pickle.load(open(DATA_PATH + '/X_val_1.pkl', 'rb'))\n",
    "y_val = pickle.load(open(DATA_PATH + '/Y_val_1.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msams3pi01\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/svyatoslav/ml/speech_denosing/wandb/run-20230418_080135-8791nj2s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sams3pi01/speech_hyper/runs/8791nj2s' target=\"_blank\">true-music-1</a></strong> to <a href='https://wandb.ai/sams3pi01/speech_hyper' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sams3pi01/speech_hyper' target=\"_blank\">https://wandb.ai/sams3pi01/speech_hyper</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sams3pi01/speech_hyper/runs/8791nj2s' target=\"_blank\">https://wandb.ai/sams3pi01/speech_hyper/runs/8791nj2s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start a run, tracking hyperparameters\n",
    "run = wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"speech_hyper\",\n",
    "\n",
    "    # track hyperparameters and run metadata with wandb.config\n",
    "    config={\n",
    "        \"activation\": \"relu\",\n",
    "        \"loss\": \"mse\",\n",
    "        \"metric\": \"rmse\",\n",
    "        \"optimizer\": \"adam\",\n",
    "        \"epoch\": 32,\n",
    "        \"batch_size\" : 2048,\n",
    "        \"learning_rate\" : 0.0005\n",
    "    }\n",
    ")\n",
    "\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 129, 8, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " zero_padding2d_2 (ZeroPadding2  (None, 137, 8, 1)   0           ['input_3[0][0]']                \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 129, 1, 18)   1296        ['zero_padding2d_2[0][0]']       \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 129, 1, 18)   0           ['conv2d_32[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 129, 1, 18)  72          ['activation_30[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 129, 1, 30)   2700        ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 129, 1, 30)   0           ['conv2d_33[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 129, 1, 30)  120         ['activation_31[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 129, 1, 8)    2160        ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 129, 1, 8)    0           ['conv2d_34[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 129, 1, 8)   32          ['activation_32[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 129, 1, 18)   1296        ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 129, 1, 18)   0           ['conv2d_35[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 129, 1, 18)  72          ['activation_33[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 129, 1, 30)   2700        ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 129, 1, 30)   0           ['conv2d_36[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 129, 1, 30)  120         ['activation_34[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 129, 1, 8)    2160        ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 129, 1, 8)    0           ['conv2d_37[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 129, 1, 8)   32          ['activation_35[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 129, 1, 18)   1296        ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 129, 1, 18)   0           ['conv2d_38[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 129, 1, 18)  72          ['activation_36[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 129, 1, 30)   2700        ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 129, 1, 30)   0           ['conv2d_39[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 129, 1, 30)  120         ['activation_37[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 129, 1, 8)    2160        ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 129, 1, 8)    0           ['conv2d_40[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 129, 1, 8)   32          ['activation_38[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 129, 1, 18)   1296        ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 129, 1, 18)   0           ['conv2d_41[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 129, 1, 18)  72          ['activation_39[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 129, 1, 30)   2700        ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TFOpLa  (None, 129, 1, 30)  0           ['conv2d_42[0][0]',              \n",
      " mbda)                                                            'conv2d_36[0][0]']              \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 129, 1, 30)   0           ['tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 129, 1, 30)  120         ['activation_40[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 129, 1, 8)    2160        ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 129, 1, 8)    0           ['conv2d_43[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 129, 1, 8)   32          ['activation_41[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 129, 1, 18)   1296        ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 129, 1, 18)   0           ['conv2d_44[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 129, 1, 18)  72          ['activation_42[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 129, 1, 30)   2700        ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TFOpLa  (None, 129, 1, 30)  0           ['conv2d_45[0][0]',              \n",
      " mbda)                                                            'conv2d_33[0][0]']              \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 129, 1, 30)   0           ['tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 129, 1, 30)  120         ['activation_43[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 129, 1, 8)    2160        ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 129, 1, 8)    0           ['conv2d_46[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 129, 1, 8)   32          ['activation_44[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " spatial_dropout2d_2 (SpatialDr  (None, 129, 1, 8)   0           ['batch_normalization_44[0][0]'] \n",
      " opout2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 129, 1, 1)    1033        ['spatial_dropout2d_2[0][0]']    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 32,933\n",
      "Trainable params: 32,373\n",
      "Non-trainable params: 560\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# BUILD A MODEL\n",
    "l2_strength = 0.0\n",
    "\n",
    "# to implement skip connections we need to use functional API\n",
    "inputs = Input(shape=[N_FEATURES, N_SEGMENTS, 1])\n",
    "model = inputs\n",
    "# -----\n",
    "model = tf.keras.layers.ZeroPadding2D(((4, 4), (0, 0)))(model)\n",
    "model = Conv2D(filters=18, kernel_size=[9, 8], strides=[1, 1], padding='valid', use_bias=False,\n",
    "               kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(model)\n",
    "model = Activation(config.activation)(model)\n",
    "model = BatchNormalization()(model)\n",
    "\n",
    "skip0 = Conv2D(filters=30, kernel_size=[5, 1], strides=[1, 1], padding='same', use_bias=False,\n",
    "               kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(model)\n",
    "model = Activation(config.activation)(skip0)\n",
    "model = BatchNormalization()(model)\n",
    "\n",
    "model = Conv2D(filters=8, kernel_size=[9, 1], strides=[1, 1], padding='same', use_bias=False,\n",
    "               kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(model)\n",
    "model = Activation(config.activation)(model)\n",
    "model = BatchNormalization()(model)\n",
    "\n",
    "# -----\n",
    "model = Conv2D(filters=18, kernel_size=[9, 1], strides=[1, 1], padding='same', use_bias=False,\n",
    "               kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(model)\n",
    "model = Activation(config.activation)(model)\n",
    "model = BatchNormalization()(model)\n",
    "\n",
    "skip1 = Conv2D(filters=30, kernel_size=[5, 1], strides=[1, 1], padding='same', use_bias=False,\n",
    "               kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(model)\n",
    "model = Activation(config.activation)(skip1)\n",
    "model = BatchNormalization()(model)\n",
    "\n",
    "model = Conv2D(filters=8, kernel_size=[9, 1], strides=[1, 1], padding='same', use_bias=False,\n",
    "               kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(model)\n",
    "model = Activation(config.activation)(model)\n",
    "model = BatchNormalization()(model)\n",
    "\n",
    "# ----\n",
    "model = Conv2D(filters=18, kernel_size=[9, 1], strides=[1, 1], padding='same', use_bias=False,\n",
    "               kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(model)\n",
    "model = Activation(config.activation)(model)\n",
    "model = BatchNormalization()(model)\n",
    "\n",
    "model = Conv2D(filters=30, kernel_size=[5, 1], strides=[1, 1], padding='same', use_bias=False,\n",
    "               kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(model)\n",
    "model = Activation(config.activation)(model)\n",
    "model = BatchNormalization()(model)\n",
    "\n",
    "model = Conv2D(filters=8, kernel_size=[9, 1], strides=[1, 1], padding='same', use_bias=False,\n",
    "               kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(model)\n",
    "model = Activation(config.activation)(model)\n",
    "model = BatchNormalization()(model)\n",
    "\n",
    "# ----\n",
    "model = Conv2D(filters=18, kernel_size=[9, 1], strides=[1, 1], padding='same', use_bias=False,\n",
    "               kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(model)\n",
    "model = Activation(config.activation)(model)\n",
    "model = BatchNormalization()(model)\n",
    "\n",
    "model = Conv2D(filters=30, kernel_size=[5, 1], strides=[1, 1], padding='same', use_bias=False,\n",
    "               kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(model)\n",
    "model = model + skip1\n",
    "model = Activation(config.activation)(model)\n",
    "model = BatchNormalization()(model)\n",
    "\n",
    "model = Conv2D(filters=8, kernel_size=[9, 1], strides=[1, 1], padding='same', use_bias=False,\n",
    "               kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(model)\n",
    "model = Activation(config.activation)(model)\n",
    "model = BatchNormalization()(model)\n",
    "\n",
    "# ----\n",
    "model = Conv2D(filters=18, kernel_size=[9, 1], strides=[1, 1], padding='same', use_bias=False,\n",
    "               kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(model)\n",
    "model = Activation(config.activation)(model)\n",
    "model = BatchNormalization()(model)\n",
    "\n",
    "model = Conv2D(filters=30, kernel_size=[5, 1], strides=[1, 1], padding='same', use_bias=False,\n",
    "               kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(model)\n",
    "model = model + skip0\n",
    "model = Activation(config.activation)(model)\n",
    "model = BatchNormalization()(model)\n",
    "\n",
    "model = Conv2D(filters=8, kernel_size=[9, 1], strides=[1, 1], padding='same', use_bias=False,\n",
    "               kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(model)\n",
    "model = Activation(config.activation)(model)\n",
    "model = BatchNormalization()(model)\n",
    "\n",
    "# ----\n",
    "model = tf.keras.layers.SpatialDropout2D(0.2)(model)\n",
    "model = Conv2D(filters=1, kernel_size=[129, 1], strides=[\n",
    "               1, 1], padding='same')(model)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=model)\n",
    "\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=config.learning_rate, epsilon = 1e-8)\n",
    "# model.compile(optimizer=optimizer, loss=config.loss, metrics=[\n",
    "#               tf.keras.metrics.RootMeanSquaredError(config.metric)])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get last artefact from w&b\n",
    "# artifact = run.use_artifact('sams3pi01/speech_denoising/run_3zig82av_model:v0', type='model')\n",
    "# artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "keras.backend.clear_session()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=config.learning_rate, epsilon = 1e-8)\n",
    "\n",
    "model = keras.models.load_model('models/')\n",
    "model.compile(optimizer=optimizer, loss=config.loss, metrics=[\n",
    "              tf.keras.metrics.RootMeanSquaredError(config.metric)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=4, mode=\"min\", restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    epochs=config.epoch,\n",
    "\n",
    "    batch_size = config.batch_size,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[\n",
    "        WandbMetricsLogger(log_freq=5),\n",
    "        WandbModelCheckpoint(\"models\"),\n",
    "        early_stopping_callback\n",
    "    ]\n",
    ")\n",
    "\n",
    "wandb.agent(sweep_id, function=train)\n",
    "model.save('model_1.h5')\n",
    "\n",
    "\n",
    "val_loss = model.evaluate(x_test, y_test)[0]\n",
    "print(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize mse\n",
    "plt.plot(history.history['rmse'])\n",
    "plt.plot(history.history['val_rmse'])\n",
    "plt.title('model rmse value')\n",
    "plt.ylabel('rmse')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech_older_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
